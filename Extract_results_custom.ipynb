{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8934348",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31b00bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:43.297369Z",
     "start_time": "2023-04-18T01:43:41.224846Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Library\n",
    "import sys\n",
    "import os\n",
    "import os.path as pth\n",
    "\n",
    "#!pip install torchplot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import nets\n",
    "import datasets\n",
    "import tools\n",
    "import layers as L\n",
    "import train\n",
    "\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from slacker import Slacker\n",
    "from quantization import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45df99c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76aeb0c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:44.608112Z",
     "start_time": "2023-04-18T01:43:44.484575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom functions - Completed\n",
    "\n",
    "@jit\n",
    "def amac(x, w):\n",
    "    return (x * w).sum()\n",
    "\n",
    "\n",
    "@jit\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "@jit\n",
    "def padding(a):\n",
    "    result = np.zeros((a.shape[0],a.shape[1]+2,a.shape[2]+2))\n",
    "    for i in range(a.shape[0]):\n",
    "        result[i] = np.pad(a[i],1)\n",
    "    return result\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def maxpooling(x_original):\n",
    "   \n",
    "    depth = x_original.shape[0] \n",
    "    row = int((x_original.shape[1])/2)\n",
    "    col = int((x_original.shape[2])/2)\n",
    "\n",
    "    one_layer = np.zeros((depth,row,col))\n",
    "    \n",
    "    for d in range(depth):\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                r = x_original[d,2*i:2*i+2,2*j:2*j+2].max()\n",
    "                one_layer[d,i,j] = r\n",
    "    return one_layer\n",
    "\n",
    "get_bin = lambda x, n: format(x, 'b').zfill(n).replace(\"-\",\"1\")\n",
    "\n",
    "\n",
    "# Partial sum function with point parameters - Completed\n",
    "\n",
    "# This is partial sum function for convolution layer -> Matches with verilog\n",
    "@jit(cache=True)\n",
    "def partial_sum_fa_conv_point(original, bit=5, point = 1):\n",
    "    a = original\n",
    "    bit = bit - 2  + (point - 1)\n",
    "    value = 1.875/(2**(point-1))\n",
    "    \n",
    "    result = np.zeros(a.shape[0])\n",
    "    for d in range(a.shape[0]):\n",
    "        partial = a[d].sum()\n",
    "        if partial > value:\n",
    "            partial = value\n",
    "        elif partial < -value:\n",
    "            partial = -value\n",
    "        else:\n",
    "            partial = partial\n",
    "        result[d] = math.trunc(partial* (2**bit)) / (2**bit)\n",
    "    return result.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This function matches with our verilog model & reasonable accuracy\n",
    "@jit(cache=True)\n",
    "def partial_sum_fa_fc_point(original, bit=5, point=1):\n",
    "    a = original\n",
    "    bit = bit - 2  + (point - 1)\n",
    "    value = 1.875/(2**(point-1))\n",
    "    \n",
    "    partial = a.sum()\n",
    "    if partial > value:\n",
    "        partial = value\n",
    "    elif partial < -value:\n",
    "        partial = -value\n",
    "    else:\n",
    "        partial = partial\n",
    "    result= math.trunc(partial* (2**bit)) / (2**bit)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b8341e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:47.866664Z",
     "start_time": "2023-04-18T01:43:47.845602Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Functions for different fixed points -> Original functions\n",
    "@jit(nopython=True)\n",
    "def quant_signed_15_np(original, bit=5):\n",
    "    bit = bit -2\n",
    "    original = np.clip(original, -1.875, 1.875)\n",
    "    original = original * (2**bit)\n",
    "    \n",
    "    (row, col) = original.shape\n",
    "    result = np.zeros((row,col))\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            result[i,j] = math.trunc(original[i,j])/ (2**bit)\n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def quant_signed_15_np_fc(original, bit=5):\n",
    "    bit = bit -2\n",
    "    original = np.clip(original, -1.875, 1.875)\n",
    "    original = original * (2**bit)\n",
    "    \n",
    "    result = math.trunc(original)/ (2**bit)\n",
    "    return result\n",
    "\n",
    "\n",
    "# FC & Conv function with point parameters\n",
    "# Problem of these functions is that they have different fixed points with bias\n",
    "# And it does not match with our verilog model\n",
    "@jit(cache=True)\n",
    "def fc_fa(x_original, w, b, p=1):\n",
    "   \n",
    "    filt = w.shape[0]\n",
    "    stage = int(x_original.shape[1]/8)\n",
    "    c = np.zeros((1,filt))\n",
    "    for f in range(filt):\n",
    "        re = 0\n",
    "        for i in range(stage):\n",
    "            r = x_original[0,i*8:i*8+8] * w[f,i*8:i*8+8]\n",
    "            re = re + partial_sum_fa_fc_point(r, point=p)\n",
    "        c[0,f] = quant_signed_15_np_fc(re + b[f])\n",
    "    return c\n",
    "\n",
    "@jit(cache=True)\n",
    "def conv_custom_fa(x_original, w, b, p=1):\n",
    "   \n",
    "    filt = w.shape[0]\n",
    "    depth = x_original.shape[0] \n",
    "    row = x_original.shape[1] - 2\n",
    "    col = x_original.shape[2] - 2\n",
    "\n",
    "    c = np.zeros((filt,row,col))\n",
    "    one_layer = np.zeros((row,col))\n",
    "    \n",
    "    for f in range(filt):\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                r = x_original[:,i:i+3,j:j+3] * w[f]\n",
    "                one_layer[i,j] = partial_sum_fa_conv_point(r, point=p)\n",
    "        c[f,:,:] = quant_signed_15_np(one_layer + b[f])\n",
    "    return c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7156fb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:49.375257Z",
     "start_time": "2023-04-18T01:43:49.349168Z"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def quant_signed_05_np(original, bit=5):\n",
    "    bit = bit -1\n",
    "    original = np.clip(original, -0.9375, 0.9375)\n",
    "    original = original * (2**bit)\n",
    "    \n",
    "    (row, col) = original.shape\n",
    "    result = np.zeros((row,col))\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            result[i,j] = math.trunc(original[i,j])/ (2**bit)\n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def quant_signed_05_np_fc(original, bit=5):\n",
    "    bit = bit -1\n",
    "    original = np.clip(original, -0.9375, 0.9375)\n",
    "    original = original * (2**bit)\n",
    "    \n",
    "    result = math.trunc(original)/ (2**bit)\n",
    "    return result\n",
    "\n",
    "\n",
    "# FC & Conv function with point parameters - completed\n",
    "# These functions have same fixed point with bias & match with verilog file\n",
    "@jit(cache=True)\n",
    "def fc_fa_05(x_original, w, b, p=1):\n",
    "   \n",
    "    filt = w.shape[0]\n",
    "    stage = int(x_original.shape[1]/8)\n",
    "    c = np.zeros((1,filt))\n",
    "    for f in range(filt):\n",
    "        re = 0\n",
    "        for i in range(stage):\n",
    "            r = x_original[0,i*8:i*8+8] * w[f,i*8:i*8+8]\n",
    "            re = re + partial_sum_fa_fc_point(r, point=p)\n",
    "        c[0,f] = quant_signed_05_np_fc(re + b[f])\n",
    "    return c\n",
    "\n",
    "@jit(cache=True)\n",
    "def conv_custom_fa_05(x_original, w, b, p=1):\n",
    "   \n",
    "    filt = w.shape[0]\n",
    "    depth = x_original.shape[0] \n",
    "    row = x_original.shape[1] - 2\n",
    "    col = x_original.shape[2] - 2\n",
    "\n",
    "    c = np.zeros((filt,row,col))\n",
    "    one_layer = np.zeros((row,col))\n",
    "    \n",
    "    for f in range(filt):\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                r = x_original[:,i:i+3,j:j+3] * w[f]\n",
    "                one_layer[i,j] = partial_sum_fa_conv_point(r, point=p)\n",
    "        c[f,:,:] = quant_signed_05_np(one_layer + b[f])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b3699",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518e0d24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:54.320202Z",
     "start_time": "2023-04-18T01:43:53.960958Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data ... \n",
      "Quant MNIST\n",
      "########## Loaded checkpoint './checkpoints_quant/mnist_quant_mnist/2_18_Time_16_36/checkpoint_7_98.3.tar'\n",
      "mnist dataset\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model and data\n",
    "\n",
    "file = open('latest.txt' , 'r' )\n",
    "line = file.readline()\n",
    "pretrained_checkpoint = line\n",
    "file.close()\n",
    "\n",
    "# Default settings for arch, dataset, and checkpoint\n",
    "arch = \"CNN_627_large\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 256\n",
    "pretrained_checkpoint = pretrained_checkpoint\n",
    "\n",
    "trainloader, _, testloader = datasets.get_mnist(batch_size)\n",
    "model = nets.mnist_quant()\n",
    "\n",
    "pretrained_ckpt = torch.load(pretrained_checkpoint)\n",
    "model.load_state_dict(pretrained_ckpt['state_dict'])\n",
    "print(\"########## Loaded checkpoint '{}'\".format(pretrained_checkpoint))\n",
    "\n",
    "print(\"mnist dataset\")\n",
    "with open(\"./data_quantized/quant_test_data_mnist.pkl\",\"rb\") as f:\n",
    "    data_list = pickle.load(f)\n",
    "with open(\"./data_quantized/quant_test_label_mnist.pkl\",\"rb\") as g:\n",
    "    label_list = pickle.load(g)\n",
    "    \n",
    "    \n",
    "# Load Weights and biases\n",
    "w1 = model.conv1.weight\n",
    "b1 = model.conv1.bias\n",
    "\n",
    "w2 = model.conv2.weight\n",
    "b2 = model.conv2.bias\n",
    "\n",
    "w3 = model.conv3.weight\n",
    "b3 = model.conv3.bias\n",
    "\n",
    "w4 = model.conv4.weight\n",
    "b4 = model.conv4.bias\n",
    "\n",
    "w5 = model.fc5.weight\n",
    "b5 = model.fc5.bias\n",
    "\n",
    "w6 = model.fc6.weight\n",
    "b6 = model.fc6.bias\n",
    "\n",
    "\n",
    "w1 = w1.data.numpy()\n",
    "b1 = b1.data.numpy()\n",
    "\n",
    "w2 = w2.data.numpy()\n",
    "b2 = b2.data.numpy()\n",
    "\n",
    "w3 = w3.data.numpy()\n",
    "b3 = b3.data.numpy()\n",
    "\n",
    "w4 = w4.data.numpy()\n",
    "b4 = b4.data.numpy()\n",
    "\n",
    "w5 = w5.data.numpy()\n",
    "b5 = b5.data.numpy()\n",
    "\n",
    "w6 = w6.data.numpy()\n",
    "b6 = b6.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06897bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:56.695575Z",
     "start_time": "2023-04-18T01:43:56.673323Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_custom_fa_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m label_list[i]\n\u001b[0;32m      3\u001b[0m x_original \u001b[38;5;241m=\u001b[39m data_list[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 5\u001b[0m a, b, c \u001b[38;5;241m=\u001b[39m \u001b[43mconv_custom_fa_plot\u001b[49m(x_original,w1,b1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_custom_fa_plot' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "y = label_list[i]\n",
    "x_original = data_list[i].view(1,32,32).numpy()\n",
    "\n",
    "a, b, c = conv_custom_fa_plot(x_original,w1,b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5130446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:43:55.445625Z",
     "start_time": "2023-04-18T01:43:55.422074Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mb\u001b[49m\u001b[38;5;241m.\u001b[39mflatten())),b\u001b[38;5;241m.\u001b[39mflatten())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(range(len(b.flatten())),b.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32433d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T00:44:51.421235Z",
     "start_time": "2023-03-29T00:44:51.230649Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(b.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd5f2d",
   "metadata": {},
   "source": [
    "# Open model and file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6f96d",
   "metadata": {},
   "source": [
    "## Save the data with different fixed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dc196e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:07.784387Z",
     "start_time": "2023-04-18T01:44:06.753549Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data ... \n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "batch_size=256\n",
    "distributed=None\n",
    "trainsampler = None\n",
    "workers=2\n",
    "\n",
    "print(\"Loading MNIST data ... \")\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=(trainsampler is None), \n",
    "              num_workers=workers, pin_memory=True, sampler=trainsampler)\n",
    "\n",
    "val_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False, download=True, transform=val_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# Saving Data\n",
    "\n",
    "# Padding\n",
    "m = nn.ConstantPad2d(2, 0)\n",
    "\n",
    "\n",
    "# Save train data\n",
    "data_train = trainset.train_data\n",
    "label_train = trainset.train_labels\n",
    "\n",
    "data_train = (data_train.int()-128)/128\n",
    "data_train = quant_signed_15(data_train)\n",
    "data_train = m(data_train)\n",
    "\n",
    "with open(\"./data_quantized/quant_data_mnist.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data_train, f)\n",
    "with open(\"./data_quantized/quant_label_mnist.pkl\",\"wb\") as g:\n",
    "    pickle.dump(label_train, g)\n",
    "    \n",
    "    \n",
    "# Save test data\n",
    "label = testset.test_labels\n",
    "data = testset.test_data\n",
    "\n",
    "data = (data.int()-128)/128\n",
    "data = quant_signed_15(data)\n",
    "data = m(data)\n",
    "\n",
    "with open(\"./data_quantized/quant_test_data_mnist.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "with open(\"./data_quantized/quant_test_label_mnist.pkl\",\"wb\") as g:\n",
    "    pickle.dump(label, g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a044d9",
   "metadata": {},
   "source": [
    "## Save the data with same fixed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e44871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:10.444678Z",
     "start_time": "2023-04-18T01:44:09.365511Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data ... \n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "batch_size=256\n",
    "distributed=None\n",
    "trainsampler = None\n",
    "workers=2\n",
    "\n",
    "print(\"Loading MNIST data ... \")\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=(trainsampler is None), \n",
    "              num_workers=workers, pin_memory=True, sampler=trainsampler)\n",
    "\n",
    "val_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False, download=True, transform=val_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# Saving Data\n",
    "\n",
    "# Padding\n",
    "m = nn.ConstantPad2d(2, 0)\n",
    "\n",
    "\n",
    "# Save train data\n",
    "data_train = trainset.train_data\n",
    "label_train = trainset.train_labels\n",
    "\n",
    "data_train = (data_train.int()-128)/128\n",
    "data_train = quant_signed_05(data_train)\n",
    "data_train = m(data_train)\n",
    "\n",
    "with open(\"./data_quantized/quant_data_mnist_05.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data_train, f)\n",
    "with open(\"./data_quantized/quant_label_mnist_05.pkl\",\"wb\") as g:\n",
    "    pickle.dump(label_train, g)\n",
    "    \n",
    "    \n",
    "# Save test data\n",
    "label = testset.test_labels\n",
    "data = testset.test_data\n",
    "\n",
    "data = (data.int()-128)/128\n",
    "data = quant_signed_05(data)\n",
    "data = m(data)\n",
    "\n",
    "with open(\"./data_quantized/quant_test_data_mnist_05.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "with open(\"./data_quantized/quant_test_label_mnist_05.pkl\",\"wb\") as g:\n",
    "    pickle.dump(label, g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c31b4f",
   "metadata": {},
   "source": [
    "# Load the model & input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7c155c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:12.131716Z",
     "start_time": "2023-04-18T01:44:12.045714Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant MNIST\n",
      "########## Loaded checkpoint './checkpoints_quant/mnist_quant_mnist/2_18_Time_16_36/checkpoint_7_98.3.tar'\n",
      "mnist dataset with different fixed point\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model and data\n",
    "\n",
    "file = open('latest.txt' , 'r' )\n",
    "line = file.readline()\n",
    "pretrained_checkpoint = line\n",
    "file.close()\n",
    "\n",
    "# Default settings for arch, dataset, and checkpoint\n",
    "arch = \"CNN_627_large\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 256\n",
    "pretrained_checkpoint = pretrained_checkpoint\n",
    "\n",
    "# trainloader, _, testloader = datasets.get_mnist(batch_size)\n",
    "model = nets.mnist_quant()\n",
    "\n",
    "pretrained_ckpt = torch.load(pretrained_checkpoint)\n",
    "model.load_state_dict(pretrained_ckpt['state_dict'])\n",
    "print(\"########## Loaded checkpoint '{}'\".format(pretrained_checkpoint))\n",
    "\n",
    "print(\"mnist dataset with different fixed point\")\n",
    "with open(\"./data_quantized/quant_test_data_mnist.pkl\",\"rb\") as f:\n",
    "    data_list = pickle.load(f)\n",
    "with open(\"./data_quantized/quant_test_label_mnist.pkl\",\"rb\") as g:\n",
    "    label_list = pickle.load(g)\n",
    "    \n",
    "\n",
    "#print(\"mnist dataset with same fixed point\")\n",
    "#with open(\"./data_quantized/quant_test_data_mnist_05.pkl\",\"rb\") as f:\n",
    "#    data_list2 = pickle.load(f)\n",
    "#with open(\"./data_quantized/quant_test_label_mnist_05.pkl\",\"rb\") as g:\n",
    "#    label_list2 = pickle.load(g)\n",
    "    \n",
    "# Load Weights and biases\n",
    "\n",
    "w1, w2, w3, w4, w5, w6 = model.conv1.weight, model.conv2.weight, model.conv3.weight, model.conv4.weight, model.fc5.weight, model.fc6.weight\n",
    "b1, b2, b3, b4, b5, b6 = model.conv1.bias, model.conv2.bias, model.conv3.bias, model.conv4.bias, model.fc5.bias, model.fc6.bias\n",
    "\n",
    "w1 = w1.data.numpy()\n",
    "b1 = b1.data.numpy()\n",
    "\n",
    "w2 = w2.data.numpy()\n",
    "b2 = b2.data.numpy()\n",
    "\n",
    "w3 = w3.data.numpy()\n",
    "b3 = b3.data.numpy()\n",
    "\n",
    "w4 = w4.data.numpy()\n",
    "b4 = b4.data.numpy()\n",
    "\n",
    "w5 = w5.data.numpy()\n",
    "b5 = b5.data.numpy()\n",
    "\n",
    "w6 = w6.data.numpy()\n",
    "b6 = b6.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783e615",
   "metadata": {},
   "source": [
    "# Save weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e6fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-11T21:13:48.919502Z",
     "start_time": "2023-03-11T21:13:48.905959Z"
    }
   },
   "source": [
    "## Save weight of first conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfa792",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# check there is a path directory, and  if not make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7aff5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def save_conv_weight(weight, bias, file_name, path):\n",
    "    if(type(path) != str):\n",
    "        path = str(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory {path} created.\")\n",
    "    # else:\n",
    "    #     print(f\"Directory {path} already exists.\")\n",
    "    if(type(file_name) != str):\n",
    "        path = str(file_name)\n",
    "    if \".txt\" not in file_name:\n",
    "        weight_name = file_name + \"_weight.txt\"\n",
    "        bias_name = file_name + \"_bias.txt\"\n",
    "    file = open(path + \"/\" + weight_name,'w')\n",
    "\n",
    "    a = weight\n",
    "    a = a * 16\n",
    "    for d in range(a.shape[1]):\n",
    "        for f in range(a.shape[0]):\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "    file = open(path + \"/\" + bias_name,'w')\n",
    "    a = bias\n",
    "    a = a * 16\n",
    "    for i in range(a.shape[0]):\n",
    "        file.write(get_bin(int(a[i]),5)+\"\\n\")\n",
    "    file.close()\n",
    "    print(f\"Save {file_name} weight to {path}/{weight_name}\\nSave {file_name} bias   to {path}/{bias_name}\")\n",
    "\n",
    "def save_fc_weight(weight, bias, file_name, path, include_bias = 0):\n",
    "    if(type(path) != str):\n",
    "        path = str(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory {path} created.\")\n",
    "    # else:\n",
    "    #     print(f\"Directory {path} already exists.\")\n",
    "    if(type(file_name) != str):\n",
    "        path = str(file_name)\n",
    "    if \".txt\" not in file_name:\n",
    "        file_name = file_name + \".txt\"\n",
    "    \n",
    "    file = open(path + \"/\" + file_name,'w')\n",
    "\n",
    "    weight = weight*16\n",
    "    bias = bias * 16\n",
    "    for w in range(0, weight.shape[0], 32):\n",
    "        for mac in range(min(weight.shape[0] - w, 32)):\n",
    "            if include_bias:\n",
    "                file.write(get_bin(int(bias[w+mac]),5)+\"\\n\")\n",
    "            else:\n",
    "                file.write(\"0\\n\")\n",
    "        for z in range(0, weight.shape[1], 8):\n",
    "            for mac in range(min(weight.shape[0] - w, 32)):\n",
    "                for port in range(8):\n",
    "                    file.write(get_bin(int(weight[w+mac,z+port]),5)+\"\\n\")\n",
    "                    \n",
    "    file.close()\n",
    "    print(f\"Save {file_name[:-4]} weight to {path}/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e20cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5dc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"weight_new\"\n",
    "\n",
    "save_conv_weight(w1, b1, \"conv1\", path)\n",
    "save_conv_weight(w2, b2, \"conv2\", path)\n",
    "save_conv_weight(w3, b3, \"conv3\", path)\n",
    "save_conv_weight(w4, b4, \"conv4\", path)\n",
    "save_fc_weight(w5, b5, \"fc5\", path)\n",
    "save_fc_weight(w6, b6, \"fc6\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66439ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T02:08:57.486180Z",
     "start_time": "2023-03-29T02:08:57.473122Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv1_weight_0311.txt','w')\n",
    "\n",
    "a = w1\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77912dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T02:09:00.953523Z",
     "start_time": "2023-03-29T02:09:00.933519Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv1_weight_0311_bias.txt','w')\n",
    "\n",
    "a = w1\n",
    "a = a * 32\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb0456",
   "metadata": {},
   "source": [
    "## Save weight of second conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6aaa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:13:37.780474Z",
     "start_time": "2023-03-23T17:13:37.747688Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv2_weight_0311.txt','w')\n",
    "\n",
    "a = w2\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2aff4",
   "metadata": {},
   "source": [
    "## Save weight of thrid conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2b611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:13:39.186668Z",
     "start_time": "2023-03-23T17:13:39.096282Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv3_weight_0311.txt','w')\n",
    "\n",
    "a = w3\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053f6dd",
   "metadata": {},
   "source": [
    "## Save weight of fourth conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117b3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:13:40.688249Z",
     "start_time": "2023-03-23T17:13:40.356381Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv4_weight_0311.txt','w')\n",
    "\n",
    "a = w4\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2b15a",
   "metadata": {},
   "source": [
    "## Save weight of fifth fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56e2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:22:57.544195Z",
     "start_time": "2023-03-23T17:22:57.538698Z"
    }
   },
   "outputs": [],
   "source": [
    "print(w5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d606b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./data_extracted/fc5_weight_0311.txt','w')\n",
    "\n",
    "a = w5\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bce477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T19:54:33.520554Z",
     "start_time": "2023-03-23T19:54:33.463344Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/fc5_weight_0311.txt','w')\n",
    "\n",
    "weight = w5*16\n",
    "\n",
    "for w in range(0, weight.shape[0], 32):\n",
    "    for mac in range(min(weight.shape[0] - w, 32)):\n",
    "#             file.write(get_bin(int(bias[w+mac]),5)+\"\\n\")\n",
    "        file.write(\"0\\n\")\n",
    "    for z in range(0, weight.shape[1], 8):\n",
    "        for mac in range(min(weight.shape[0] - w, 32)):\n",
    "            for port in range(8):\n",
    "                file.write(get_bin(int(weight[w+mac,z+port]),5)+\"\\n\")\n",
    "                \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7625fa2",
   "metadata": {},
   "source": [
    "## Save weight of sixth fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0b1f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T19:54:35.206091Z",
     "start_time": "2023-03-23T19:54:35.194705Z"
    }
   },
   "outputs": [],
   "source": [
    "print(w6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./data_extracted/fc6_weight_0311.txt','w')\n",
    "\n",
    "a = w6\n",
    "a = a * 16\n",
    "for d in range(a.shape[1]):\n",
    "    for f in range(a.shape[0]):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                file.write(get_bin(int(a[f,d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09413e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T19:54:36.654402Z",
     "start_time": "2023-03-23T19:54:36.634397Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/fc6_weight_0311.txt','w')\n",
    "\n",
    "weight = w6*16\n",
    "\n",
    "for w in range(0, weight.shape[0], 32):\n",
    "    for mac in range(min(weight.shape[0] - w, 32)):\n",
    "#             file.write(get_bin(int(bias[w+mac]),5)+\"\\n\")\n",
    "        file.write(\"0\\n\")\n",
    "    for z in range(0, weight.shape[1], 8):\n",
    "        for mac in range(min(weight.shape[0] - w, 32)):\n",
    "            for port in range(8):\n",
    "                file.write(get_bin(int(weight[w+mac,z+port]),5)+\"\\n\")\n",
    "                \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41071ded",
   "metadata": {},
   "source": [
    "# Save bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696166ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:10:38.231795Z",
     "start_time": "2023-03-23T17:10:38.221370Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b5241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:11:10.860483Z",
     "start_time": "2023-03-23T17:11:10.845941Z"
    }
   },
   "outputs": [],
   "source": [
    "b1.shape\n",
    "file = open('./data_extracted/conv1_bias_0311.txt','w')\n",
    "\n",
    "a = b1\n",
    "a = a * 16\n",
    "for i in range(a.shape[0]):\n",
    "    file.write(get_bin(int(a[i]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e10bc",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30a720",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71dbd253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:41.081596Z",
     "start_time": "2023-04-18T01:44:41.061808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., -8., -8., -8., -8., -8., -8.,  5.,  7.,  7.,  7.,  7.,\n",
       "        7.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  2., -4., -8., -8.,\n",
       "       -8., -8., -8., -8.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "y = label_list[i]\n",
    "x_original = data_list[i].view(1,32,32).numpy()\n",
    "x_original[0][10] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f7ea93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:38.050261Z",
     "start_time": "2023-04-18T01:44:38.034487Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_list2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m label_list[i]\n\u001b[1;32m----> 3\u001b[0m x_original \u001b[38;5;241m=\u001b[39m \u001b[43mdata_list2\u001b[49m[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m x_original[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_list2' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "y = label_list[i]\n",
    "x_original = data_list2[i].view(1,32,32).numpy()\n",
    "x_original[0][10] * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "570ca9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:48.997367Z",
     "start_time": "2023-04-18T01:44:48.981538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1024)\n"
     ]
    }
   ],
   "source": [
    "x_original = data_list[0].view(1,32,32)\n",
    "print((x_original == quant_signed_15(x_original)).sum())\n",
    "x_original = quant_signed_15(x_original)\n",
    "\n",
    "x = x_original\n",
    "x = x*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916b8287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:44:53.762448Z",
     "start_time": "2023-04-18T01:44:53.754029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8.,\n",
       "        -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8., -8.,\n",
       "        -8., -8.,  0.,  0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bin(int(x[d,i,j]),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070b3a5",
   "metadata": {},
   "source": [
    "## Input save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eab17b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:40.878106Z",
     "start_time": "2023-03-29T01:02:40.863672Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/conv1_input_0317.txt','w')\n",
    "# x_original = torch.randn(1, 32,32)\n",
    "x_original = data_list[0].view(1,32,32)\n",
    "print((x_original == quant_signed_15(x_original)).sum())\n",
    "x_original = quant_signed_15(x_original)\n",
    "\n",
    "x = x_original\n",
    "x = x*8\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(x[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97fbaa",
   "metadata": {},
   "source": [
    "## First conv result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f1aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:42.369653Z",
     "start_time": "2023-03-29T01:02:41.668744Z"
    }
   },
   "outputs": [],
   "source": [
    "b1 = np.zeros(32)\n",
    "x = x_original\n",
    "x = padding(x)\n",
    "#x = conv_custom_fa_wo_quant(x,w1,b1)\n",
    "x = conv_custom_fa(x,w1,b1, p=1)\n",
    "\n",
    "\n",
    "file = open('./data_extracted/conv1_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(save[d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252b8c1",
   "metadata": {},
   "source": [
    "## First relu&pool result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c83d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:42.608452Z",
     "start_time": "2023-03-29T01:02:42.590363Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(maxpooling(x))\n",
    "\n",
    "file = open('./data_extracted/pool_relu1_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(save[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85c861",
   "metadata": {},
   "source": [
    "## Second conv result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9a12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:43.498542Z",
     "start_time": "2023-03-29T01:02:43.335711Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b2 = np.zeros(64)\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w2,b2, p=1)\n",
    "\n",
    "file = open('./data_extracted/conv2_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(save[d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeaa47a",
   "metadata": {},
   "source": [
    "## Second relu & pool result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd834a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:44.500060Z",
     "start_time": "2023-03-29T01:02:44.485280Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(maxpooling(x))\n",
    "\n",
    "file = open('./data_extracted/pool_relu2_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(save[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44df57f",
   "metadata": {},
   "source": [
    "## Thrid conv result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a383b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:45.280135Z",
     "start_time": "2023-03-29T01:02:45.231366Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b3 = np.zeros(128)\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w3,b3, p=1)\n",
    "\n",
    "file = open('./data_extracted/conv3_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(save[d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b211dc3",
   "metadata": {},
   "source": [
    "## Thrid pool & relu result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0943ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:45.963140Z",
     "start_time": "2023-03-29T01:02:45.943705Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(maxpooling(x))\n",
    "\n",
    "file = open('./data_extracted/pool_relu3_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(save[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa400cd",
   "metadata": {},
   "source": [
    "## Fourth conv result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3922fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:46.622683Z",
     "start_time": "2023-03-29T01:02:46.586151Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b4 = np.zeros(256)\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w4,b4, p=1)\n",
    "\n",
    "file = open('./data_extracted/conv4_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(save[d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b29f37",
   "metadata": {},
   "source": [
    "## Fourth pool & relu result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637f361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T01:02:47.359526Z",
     "start_time": "2023-03-29T01:02:47.346528Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(maxpooling(x))\n",
    "\n",
    "file = open('./data_extracted/pool_relu4_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(save[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc945a3b",
   "metadata": {},
   "source": [
    "## Fifth fc result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9b48f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T01:15:06.125009Z",
     "start_time": "2023-03-28T01:15:05.696181Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b5 = np.zeros(32)\n",
    "\n",
    "x = fc_fa(x,w5,b5, p=1)\n",
    "\n",
    "file = open('./data_extracted/fc5_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "            file.write(get_bin(int(save[d,i]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d04c97",
   "metadata": {},
   "source": [
    "## Fifth relu result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9dfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T01:14:49.856831Z",
     "start_time": "2023-03-28T01:14:49.837127Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(x)\n",
    "\n",
    "file = open('./data_extracted/relu5_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "            file.write(get_bin(int(save[d,i]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc635f",
   "metadata": {},
   "source": [
    "## Sixth fc result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ede74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T01:14:51.540316Z",
     "start_time": "2023-03-28T01:14:50.975764Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b6 = np.zeros(10)\n",
    "\n",
    "x = fc_fa(x,w6,b6, p=1)\n",
    "\n",
    "file = open('./data_extracted/fc6_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "            file.write(get_bin(int(save[d,i]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1f12f",
   "metadata": {},
   "source": [
    "## Sixth relu result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b27dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T00:59:26.060002Z",
     "start_time": "2023-03-28T00:59:26.037818Z"
    }
   },
   "outputs": [],
   "source": [
    "x = relu(x)\n",
    "\n",
    "file = open('./data_extracted/relu6_output_0317.txt','w')\n",
    "\n",
    "save = x*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "            file.write(get_bin(int(save[d,i]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa46a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T00:59:26.575725Z",
     "start_time": "2023-03-28T00:59:26.532182Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e84d7c",
   "metadata": {},
   "source": [
    "# Need to organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccbc21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T00:32:10.722396Z",
     "start_time": "2023-02-23T00:32:10.607130Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df1058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T00:30:06.972998Z",
     "start_time": "2023-02-23T00:30:06.855430Z"
    }
   },
   "outputs": [],
   "source": [
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "print(x.shape)\n",
    "plt.hist(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc42a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T00:30:48.373925Z",
     "start_time": "2023-02-23T00:30:40.616508Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "b3 = np.zeros(128)\n",
    "x = padding(x)\n",
    "x, mid = conv_custom_fa_plot(x,w3,b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8487b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T21:36:47.705786Z",
     "start_time": "2023-02-22T21:33:35.689629Z"
    }
   },
   "outputs": [],
   "source": [
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = padding(x)\n",
    "x = conv_custom_fa_test(x,w4,b4)\n",
    "x = maxpooling(x)\n",
    "x = relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5e5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e2aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfff460",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mnist dataset\")\n",
    "with open(\"./data_quantized/quant_data_mnist.pkl\",\"rb\") as f:\n",
    "    data_list = pickle.load(f)\n",
    "with open(\"./data_quantized/quant_label_mnist.pkl\",\"rb\") as g:\n",
    "    label_list = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4295ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T20:12:47.977162Z",
     "start_time": "2023-02-22T20:12:47.944815Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('./data_extracted/input.txt','w')\n",
    "# x_original = torch.randn(1, 32,32)\n",
    "x_original = data_list[0].view(1,32,32)\n",
    "print((x_original == quant_signed_15(x_original)).sum())\n",
    "x_original = quant_signed_15(x_original)\n",
    "\n",
    "x = x_original\n",
    "x = x*8\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            file.write(get_bin(int(x[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141260e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T20:12:48.630639Z",
     "start_time": "2023-02-22T20:12:48.558589Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"--------------shape----------------\")\n",
    "print(x_original.shape)\n",
    "\n",
    "x = x_original.numpy()\n",
    "x = padding(x)\n",
    "\n",
    "result_original = conv_custom_fa(x, w1, b1)\n",
    "result = result_original*8\n",
    "\n",
    "\n",
    "print(result_original.shape)\n",
    "print(sum(sum(sum(result >= 16))))\n",
    "\n",
    "file = open('./data_extracted/output/conv1_output.txt','w')\n",
    "\n",
    "x = result\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(x[d,i,j]),5)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb102d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2b291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb389f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T00:57:31.102750Z",
     "start_time": "2023-02-23T00:57:31.087065Z"
    }
   },
   "outputs": [],
   "source": [
    "x = maxpooling(x)\n",
    "x = relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./data_extracted/output/acc1__custom_output.txt','w')\n",
    "\n",
    "save = mid*8\n",
    "for d in range(x.shape[0]):\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            #print(x[d,i,j])\n",
    "            file.write(get_bin(int(save[d,i,j]),10)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f66e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T22:20:20.856953Z",
     "start_time": "2023-02-23T22:20:18.161565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x_original\n",
    "print(x.shape)\n",
    "b1 = np.zeros(32)\n",
    "x = padding(x)\n",
    "x, mid, before_sum = conv_custom_fa_plot(x,w1,b1)\n",
    "plt.hist(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f25e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T01:14:36.507222Z",
     "start_time": "2023-02-23T01:14:36.386299Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d4698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ce97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T00:58:03.067897Z",
     "start_time": "2023-02-23T00:58:02.957413Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(mid.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b020b1",
   "metadata": {},
   "source": [
    "# Test One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1622073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T21:23:40.794010Z",
     "start_time": "2023-03-15T21:23:40.654664Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and data\n",
    "\n",
    "file = open('latest.txt' , 'r' )\n",
    "line = file.readline()\n",
    "pretrained_checkpoint = line\n",
    "file.close()\n",
    "\n",
    "# Default settings for arch, dataset, and checkpoint\n",
    "arch = \"CNN_627_large\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 256\n",
    "pretrained_checkpoint = pretrained_checkpoint\n",
    "\n",
    "trainloader, _, testloader = datasets.get_mnist(batch_size)\n",
    "model = nets.mnist_quant()\n",
    "\n",
    "pretrained_ckpt = torch.load(pretrained_checkpoint)\n",
    "model.load_state_dict(pretrained_ckpt['state_dict'])\n",
    "print(\"########## Loaded checkpoint '{}'\".format(pretrained_checkpoint))\n",
    "\n",
    "print(\"mnist dataset\")\n",
    "with open(\"./data_quantized/quant_test_data_mnist.pkl\",\"rb\") as f:\n",
    "    data_list = pickle.load(f)\n",
    "with open(\"./data_quantized/quant_test_label_mnist.pkl\",\"rb\") as g:\n",
    "    label_list = pickle.load(g)\n",
    "    \n",
    "    \n",
    "# Load Weights and biases\n",
    "w1 = model.conv1.weight\n",
    "b1 = model.conv1.bias\n",
    "\n",
    "w2 = model.conv2.weight\n",
    "b2 = model.conv2.bias\n",
    "\n",
    "w3 = model.conv3.weight\n",
    "b3 = model.conv3.bias\n",
    "\n",
    "w4 = model.conv4.weight\n",
    "b4 = model.conv4.bias\n",
    "\n",
    "w5 = model.fc5.weight\n",
    "b5 = model.fc5.bias\n",
    "\n",
    "w6 = model.fc6.weight\n",
    "b6 = model.fc6.bias\n",
    "\n",
    "\n",
    "w1 = w1.data.numpy()\n",
    "b1 = b1.data.numpy()\n",
    "\n",
    "w2 = w2.data.numpy()\n",
    "b2 = b2.data.numpy()\n",
    "\n",
    "w3 = w3.data.numpy()\n",
    "b3 = b3.data.numpy()\n",
    "\n",
    "w4 = w4.data.numpy()\n",
    "b4 = b4.data.numpy()\n",
    "\n",
    "w5 = w5.data.numpy()\n",
    "b5 = b5.data.numpy()\n",
    "\n",
    "w6 = w6.data.numpy()\n",
    "b6 = b6.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce071b",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d20b31",
   "metadata": {},
   "source": [
    "## With different fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a13dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T23:15:16.699553Z",
     "start_time": "2023-04-03T23:14:57.116510Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_custom_fa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hyunwon\\cnn\\cnn_quant\\cnn_cifar10\\Extract_results_custom.ipynb Cell 105\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hyunwon/cnn/cnn_quant/cnn_cifar10/Extract_results_custom.ipynb#Y212sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m data_list[i]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hyunwon/cnn/cnn_quant/cnn_cifar10/Extract_results_custom.ipynb#Y212sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x \u001b[39m=\u001b[39m padding(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hyunwon/cnn/cnn_quant/cnn_cifar10/Extract_results_custom.ipynb#Y212sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x \u001b[39m=\u001b[39m conv_custom_fa(x,w1,b1, p\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hyunwon/cnn/cnn_quant/cnn_cifar10/Extract_results_custom.ipynb#Y212sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m maxpooling(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hyunwon/cnn/cnn_quant/cnn_cifar10/Extract_results_custom.ipynb#Y212sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x \u001b[39m=\u001b[39m reul(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_custom_fa' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate with Custom model\n",
    "correct = 0\n",
    "for i in range(256):\n",
    "\n",
    "    y = label_list[i]\n",
    "\n",
    "    x = data_list[i].view(1,32,32).numpy()\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa(x,w1,b1, p=1)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa(x,w2,b2, p=2)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa(x,w3,b3, p=3)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa(x,w4,b4, p=4)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = x.reshape(1,1024)\n",
    "\n",
    "    x = fc_fa(x,w5,b5, p=3)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = fc_fa(x,w6,b6, p=1)\n",
    "\n",
    "\n",
    "    if (np.argmax(x) == y.item()):\n",
    "        correct += 1\n",
    "\n",
    "print(correct/(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9727980",
   "metadata": {},
   "source": [
    "## With same fixed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a4616e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T23:14:33.146159Z",
     "start_time": "2023-04-03T23:14:14.628644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83203125\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with Custom model\n",
    "correct = 0\n",
    "#randlist = random.sample(range(0, 10000), 256)\n",
    "randlist = [i for i in range(256)]\n",
    "for i in randlist:\n",
    "\n",
    "    y = label_list[i]\n",
    "    x = data_list[i].view(1,32,32).numpy()\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa_05(x,w1,b1, p=1)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa_05(x,w2,b2, p=2)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa_05(x,w3,b3, p=3)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = padding(x)\n",
    "    x = conv_custom_fa_05(x,w4,b4, p=4)\n",
    "    x = maxpooling(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = x.reshape(1,1024)\n",
    "\n",
    "    x = fc_fa_05(x,w5,b5, p=3)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = fc_fa_05(x,w6,b6, p=1)\n",
    "\n",
    "\n",
    "    if (np.argmax(x) == y.item()):\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(randlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb68087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5625 -0.5625 -0.5625 ... -0.5625 -0.5625 -0.5625]\n",
      " [-0.5625 -0.4375 -0.4375 ... -0.9375 -0.9375 -0.5625]\n",
      " [-0.5625 -0.4375 -0.6875 ... -0.9375 -0.9375 -0.5625]\n",
      " ...\n",
      " [-0.5625 -0.9375 -0.9375 ... -0.4375 -0.0625 -0.5625]\n",
      " [-0.5625 -0.9375 -0.9375 ... -0.0625 -0.0625 -0.5625]\n",
      " [-0.5625 -0.5625 -0.5625 ... -0.5625 -0.5625 -0.5625]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "y = label_list[i]\n",
    "# print(y)\n",
    "x = data_list[i].view(1,32,32).numpy()\n",
    "\n",
    "x = padding(x)\n",
    "# print(x[0][10])\n",
    "x = conv_custom_fa_05(x,w1,b1, p=1)\n",
    "# print(x[0])\n",
    "# x = maxpooling(x)\n",
    "# x = relu(x)\n",
    "\n",
    "# x = padding(x)\n",
    "# x = conv_custom_fa_05(x,w2,b2, p=2)\n",
    "# x = maxpooling(x)\n",
    "# x = relu(x)\n",
    "\n",
    "print(x[10])\n",
    "# x = padding(x)\n",
    "# x = conv_custom_fa_05(x,w3,b3, p=3)\n",
    "# x = maxpooling(x)\n",
    "# x = relu(x)\n",
    "\n",
    "# x = padding(x)\n",
    "# x = conv_custom_fa_05(x,w4,b4, p=4)\n",
    "# x = maxpooling(x)\n",
    "# x = relu(x)\n",
    "\n",
    "# x = x.reshape(1,1024)\n",
    "# for i in range(1024):\n",
    "#     print(x[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74fd773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5625, -0.5625, -0.5625, ..., -0.5625, -0.5625, -0.5625],\n",
       "       [-0.5625, -0.4375, -0.4375, ..., -0.9375, -0.9375, -0.5625],\n",
       "       [-0.5625, -0.4375, -0.6875, ..., -0.9375, -0.9375, -0.5625],\n",
       "       ...,\n",
       "       [-0.5625, -0.9375, -0.9375, ..., -0.4375, -0.0625, -0.5625],\n",
       "       [-0.5625, -0.9375, -0.9375, ..., -0.0625, -0.0625, -0.5625],\n",
       "       [-0.5625, -0.5625, -0.5625, ..., -0.5625, -0.5625, -0.5625]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_signed_05_np(x[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888e30a",
   "metadata": {},
   "source": [
    "## Torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af967125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T01:15:36.004864Z",
     "start_time": "2023-02-24T01:15:35.045341Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate with Torch model\n",
    "correct = 0\n",
    "randlist = random.sample(range(0, 10000), 256)\n",
    "for i in randlist:    \n",
    "    y = label_list[i]\n",
    "    x = data_list[i].view(1,32,32)\n",
    "    \n",
    "    x = model.conv1(x)\n",
    "    x = model.pool1(F.relu(x))\n",
    "    #x = quant_signed_15(x)\n",
    "\n",
    "    x = model.conv2(x)\n",
    "    x = model.pool2(F.relu(x))\n",
    "    #x = quant_signed_15(x)\n",
    "\n",
    "    x = model.conv3(x)\n",
    "    x = model.pool3(F.relu(x))\n",
    "    #x = quant_signed_15(x)\n",
    "\n",
    "\n",
    "    x = model.conv4(x)\n",
    "    x = model.pool4(F.relu(x))\n",
    "    #x = quant_signed_15(x)\n",
    "\n",
    "\n",
    "    x = x.view(1,-1)\n",
    "    x = model.fc5(x)\n",
    "    #x = quant_signed_15(x)\n",
    "    x = F.relu(x)\n",
    "\n",
    "    x = model.fc6(x)\n",
    "    #x = quant_signed_15(x)\n",
    "\n",
    "    index_min1 = np.argmax(x.detach().numpy())\n",
    "    if (index_min1 == y.item()):\n",
    "        correct += 1\n",
    "print(correct/len(randlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4135b8",
   "metadata": {},
   "source": [
    "## Compar the result of two model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668607b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T00:59:54.529085Z",
     "start_time": "2023-03-29T00:59:52.828279Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Start compare\n",
    "\n",
    "# Custom model\n",
    "i = 10\n",
    "x = data_list[i].view(1,32,32).numpy()\n",
    "\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w1,b1)\n",
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w2,b2)\n",
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w3,b3)\n",
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = padding(x)\n",
    "x = conv_custom_fa(x,w4,b4)\n",
    "x = maxpooling(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = x.reshape(1,1024)\n",
    "\n",
    "x = fc_fa(x,w5,b5)\n",
    "\n",
    "x1 = x\n",
    "\n",
    "# Torch model\n",
    "\n",
    "x = data_list[i].view(1,32,32)\n",
    "\n",
    "x = model.conv1(x)\n",
    "x = model.pool1(F.relu(x))\n",
    "\n",
    "x = model.conv2(x)\n",
    "x = model.pool2(F.relu(x))\n",
    "\n",
    "x = model.conv3(x)\n",
    "x = model.pool3(F.relu(x))\n",
    "\n",
    "\n",
    "x = model.conv4(x)\n",
    "x = model.pool4(F.relu(x))\n",
    "\n",
    "x = x.view(1,-1)\n",
    "\n",
    "x = model.fc5(x)\n",
    "\n",
    "x2 = x\n",
    "\n",
    "print(x1.shape, x2.shape)\n",
    "\n",
    "if len(x1.shape) == 3:\n",
    "    print(\"Conv Layer\")\n",
    "    a = x.shape[0]\n",
    "    b = x.shape[1]\n",
    "    c = x.shape[2]\n",
    "\n",
    "\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            for k in range(c):\n",
    "                if (x1[i][j][k] == x2[i][j][k].item()) == False:\n",
    "                    print(x1[i][j][k] == x2[i][j][k].item())\n",
    "                else:\n",
    "                    print(\"Good\")\n",
    "elif len(x1.shape) == 2:\n",
    "    print(\"FC Layer\")\n",
    "    a = x.shape[0]\n",
    "    b = x.shape[1]\n",
    "\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            if (x1[i][j] == x2[i][j].item()) == False:\n",
    "                print(x1[i][j] ,x2[i][j].item())\n",
    "            else:\n",
    "                print(\"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6bea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "770.875px",
    "left": "22px",
    "top": "110.1px",
    "width": "301.025px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "337.424px",
    "left": "1107.66px",
    "right": "20px",
    "top": "49.9829px",
    "width": "599.328px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
